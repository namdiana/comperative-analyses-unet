{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52b4446-606b-4319-9b1d-04fd79fd2fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2, ast\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad58dbb-b83c-4454-bc12-e6976890dfa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_df = pd.read_pickle('lung_cancer_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa26ad6-fcc2-4dcf-8623-5c91b008eeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"vgg11\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812e7aaa-8787-4108-b5be-d592bbfece7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coeff(pred, target):\n",
    "    m1 = np.array(pred).flatten()\n",
    "    m2 = np.array(target).flatten()\n",
    "    intersection = np.sum(m1 * m2)\n",
    "    if (m1.sum() + m2.sum()) == 0: \n",
    "        return 0 \n",
    "    else: \n",
    "        return (2. * intersection ) / (m1.sum() + m2.sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2a9e2a-9a61-472e-8f3b-00ed3f44b30e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9117644-925f-4985-a2b0-b610a2150046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(val_df['mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f3bb44-52c7-4cc3-a846-a15662e4266c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_dice_coefficient(mask_true, mask_pred):\n",
    "    intersection = np.sum(mask_true * mask_pred)\n",
    "    union = np.sum(mask_true) + np.sum(mask_pred)\n",
    "    \n",
    "    dice_coefficient = (2.0 * intersection) / (union + 1e-8)  # Добавляем маленькое значение для избежания деления на ноль\n",
    "    \n",
    "    return dice_coefficient\n",
    "\n",
    "def precision_score(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    total_pixel_pred = np.sum(pred_mask)\n",
    "    precision = np.mean((intersect++ 1e-8)/(total_pixel_pred++ 1e-8))\n",
    "    return precision\n",
    "\n",
    "def recall_score(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    total_pixel_truth = np.sum(groundtruth_mask)\n",
    "    recall = np.mean((intersect+ 1e-8)/(total_pixel_truth+ 1e-8))\n",
    "    return recall\n",
    "\n",
    "def calculate_iou(mask_true, mask_pred):\n",
    "    intersection = np.sum(mask_true * mask_pred)\n",
    "    union = np.sum(mask_true) + np.sum(mask_pred) - intersection\n",
    "    \n",
    "    iou = (intersection + 1e-8) / (union + 1e-8)  # Добавляем маленькое значение для избежания деления на ноль\n",
    "    \n",
    "    return iou\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def hausdorff_distance(mask1, mask2):\n",
    "    # Получение координат точек в масках\n",
    "    coords_mask1 = np.transpose(np.nonzero(mask1))\n",
    "    coords_mask2 = np.transpose(np.nonzero(mask2))\n",
    "\n",
    "    # Вычисление расстояний между всеми точками в двух масках\n",
    "    distances_mask1_to_mask2 = cdist(coords_mask1, coords_mask2)\n",
    "    distances_mask2_to_mask1 = cdist(coords_mask2, coords_mask1)\n",
    "\n",
    "    # Нахождение максимального расстояния для каждой маски\n",
    "    max_distance_mask1 = np.max(np.min(distances_mask1_to_mask2, axis=1))\n",
    "    max_distance_mask2 = np.max(np.min(distances_mask2_to_mask1, axis=1))\n",
    "\n",
    "    # Вычисление дистанции Хаусдорфа\n",
    "    hausdorff_distance = max(max_distance_mask1, max_distance_mask2)\n",
    "\n",
    "    return hausdorff_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18051da-1a75-49f4-abad-9a4d41fbb4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(pretrained_weights, method_name):\n",
    "    model.load_state_dict(torch.load(pretrained_weights))\n",
    "    model.eval()\n",
    "    print('augmentation method name: ' + method_name)\n",
    "    d = []\n",
    "    iou = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    labels = val_df['label1'].unique()\n",
    "    for j in labels:\n",
    "        dices = []\n",
    "        test = val_df.loc[val_df['label1'] == j].reset_index(drop=True)\n",
    "        for i in range(len(test)):\n",
    "            #new_shape = [224,224]\n",
    "            mask = test['mask'][i]\n",
    "            img = test['hu_array'][i]\n",
    "            img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
    "            img = exposure.equalize_adapthist(img/np.max(img))\n",
    "            img = img.astype(np.float64)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            img = img.float()\n",
    "            img = img.cuda()\n",
    "            masks = mask.astype(int)\n",
    "            outputs = model(img)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            try:\n",
    "                mask_pred = (outputs.cpu().detach().numpy() >= 0.5) ** 2\n",
    "            except:\n",
    "                mask_pred = np.zeros([512,512])\n",
    "            dices.append(calculate_dice_coefficient(masks, mask_pred))\n",
    "            d.append(calculate_dice_coefficient(masks, mask_pred))\n",
    "            iou.append(calculate_iou(masks, mask_pred))\n",
    "            prec.append(precision_score(masks, mask_pred))\n",
    "            rec.append(recall_score(masks, mask_pred))\n",
    "        print(\"Dice for \" + j + \" \" + str(np.mean(dices))+\" \" +str(len(dices)))\n",
    "    print(\"Average\") \n",
    "    print(\"DICE \" + str(np.mean(d)))\n",
    "    print(\"IoU \" + str(np.mean(iou)))\n",
    "    print(\"precision \" + str(np.mean(prec)))\n",
    "    print(\"recall \"+str(np.mean(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44ecc75-9d74-489f-988e-a86eda678328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: original images\n",
      "Dice for LR2 0.19973851536424553 35\n",
      "Dice for LR3 0.3650203799370373 37\n",
      "Dice for LR4A 0.19791078606168003 97\n",
      "Dice for LR4B 0.6127724875295943 95\n",
      "Average\n",
      "DICE 0.37086111613149014\n",
      "IoU 0.3120575950341886\n",
      "precision 0.817595949951946\n",
      "recall 0.3590172935386154\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net.pth','original images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d4772d-e00d-4d34-98d6-67bf1fd939a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: mirror flip\n",
      "Dice for LR2 0.059457690248677725 35\n",
      "Dice for LR3 0.30914355388546594 37\n",
      "Dice for LR4A 0.34418772956888094 97\n",
      "Dice for LR4B 0.5938172845342824 95\n",
      "Average\n",
      "DICE 0.3913567517098645\n",
      "IoU 0.32441175523173865\n",
      "precision 0.8729816500374685\n",
      "recall 0.3568079688470004\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_real_mirroflip.pth','mirror flip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0732ac-7670-4145-be13-27b84369a5de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: rotate the image\n",
      "Dice for LR2 0.017810760665590442 35\n",
      "Dice for LR3 0.3113850298663808 37\n",
      "Dice for LR4A 0.32398943497859894 97\n",
      "Dice for LR4B 0.5581194431420177 95\n",
      "Average\n",
      "DICE 0.3658823674991194\n",
      "IoU 0.30751890274276233\n",
      "precision 0.8697678593680213\n",
      "recall 0.3196584160067678\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_real_rotate_image.pth','rotate the image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a605b4d1-d8f4-4dd9-be96-f6a70366540e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: Rotate the cancer\n",
      "Dice for LR2 0.02907268169916018 35\n",
      "Dice for LR3 0.2942263414687766 37\n",
      "Dice for LR4A 0.08646201909445232 97\n",
      "Dice for LR4B 0.5426080655237386 95\n",
      "Average\n",
      "DICE 0.27211553246489545\n",
      "IoU 0.2191039259703703\n",
      "precision 0.887933179607625\n",
      "recall 0.22500329297878513\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_real_rotate_cancer.pth','Rotate the cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2803a75c-63e2-41dc-80b2-353e1581236f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: Noise to image\n",
      "Dice for LR2 0.016254193179330773 35\n",
      "Dice for LR3 0.31750433289079094 37\n",
      "Dice for LR4A 0.13144496021883761 97\n",
      "Dice for LR4B 0.6166499525372229 95\n",
      "Average\n",
      "DICE 0.3168502413276488\n",
      "IoU 0.25962533868550625\n",
      "precision 0.7967260687902709\n",
      "recall 0.29120305021594084\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_real_noise_cancer.pth','Noise to image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "840ab337-36dd-4ad2-a2bc-55cf46f6814d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: Noise to cancer\n",
      "Dice for LR2 0.05465637558315465 35\n",
      "Dice for LR3 0.2993911290357784 37\n",
      "Dice for LR4A 0.2759910528865982 97\n",
      "Dice for LR4B 0.5360192098038877 95\n",
      "Average\n",
      "DICE 0.3434977347769075\n",
      "IoU 0.2832515440098847\n",
      "precision 0.8490878007510665\n",
      "recall 0.30254330480478825\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_real_noise_image.pth','Noise to cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e215c0-3d84-4c0e-b9ac-ea8ccacf9226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: Gaussian blur\n",
      "Dice for LR2 0.005370203000091529 35\n",
      "Dice for LR3 0.11041599588968411 37\n",
      "Dice for LR4A 0.12750948632251718 97\n",
      "Dice for LR4B 0.42810012917405277 95\n",
      "Average\n",
      "DICE 0.21708818711265418\n",
      "IoU 0.1600782485429789\n",
      "precision 0.954241071618539\n",
      "recall 0.16937242814095313\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_gaussian_bluring.pth','Gaussian blur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a906873c-9592-453d-adc0-ec6a676556fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: GAN\n",
      "Dice for LR2 0.07938721902507102 35\n",
      "Dice for LR3 0.3176397166939681 37\n",
      "Dice for LR4A 0.3382312943321709 97\n",
      "Dice for LR4B 0.613634722487361 95\n",
      "Average\n",
      "DICE 0.4001324104927052\n",
      "IoU 0.3347787145394898\n",
      "precision 0.7900838486806255\n",
      "recall 0.37936621538175674\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_GAN_aug.pth','GAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87fb95a4-13bc-40a1-addb-6e1b15c56a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: VAE\n",
      "Dice for LR2 0.016184041180478198 35\n",
      "Dice for LR3 0.34612719441082934 37\n",
      "Dice for LR4A 0.3896356018132116 97\n",
      "Dice for LR4B 0.6261735564257335 95\n",
      "Average\n",
      "DICE 0.4191450336016804\n",
      "IoU 0.3541060241352839\n",
      "precision 0.7818384845334759\n",
      "recall 0.38985257734752915\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/u-net_VAE_aug.pth','VAE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "u-net",
   "language": "python",
   "name": "u-net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
